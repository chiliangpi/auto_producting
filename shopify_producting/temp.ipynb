{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T10:31:26.767409Z",
     "start_time": "2023-09-14T10:31:26.309461Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from paddleocr import PPStructure,draw_structure_result,save_structure_res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T10:36:33.302121Z",
     "start_time": "2023-09-14T10:36:33.259050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "#Role\n",
    "商品信息采集师\n",
    "#Background\n",
    "我为你提供一些商品信息，但是格式不规范，请帮我提取商品的主要信息，并规范化输出\n",
    "#Workflows\n",
    "--提取商品原始标题original_title，不要有任何删减和修改；\n",
    "--商品信息概述description，要求信息完整且简明扼要，突出关键词，字数尽量控制在30-50个之间；\n",
    "--概括一个简短且个性化的标题brief_title，不超过10个单词；\n",
    "--总结SEO标题seo_title，不超过30个单词；\n",
    "--推断谷歌商品类别google_category；\n",
    "--推断shopify商品类别shopify_category；\n",
    "--推断商品类型type；\n",
    "--推断商品标签tags，数量不超过5个，使用逗号分隔；\n",
    "--推断受众群体性别gender，在male，female，unisex中选择;\n",
    "--推断受众群体年龄age_group，在child，adult中选择;\n",
    "--推断广告词分组adword_group，数量不超过3个，逗号分隔;\n",
    "--推断广告词标签adword_labels，数量不超过5个，逗号分隔；\n",
    "--提取商品MPN编号mpn_code，如果找不到则为’';\n",
    "--提取sku信息sku_details，包括sku属性分类、属性内容、对应的价格，格式为嵌套Json，如果某属性没有价格，则价格为''；\n",
    "--提取商品的最高价格highest_price，如果只存在一个价格，只输出该价格，如果存在多个价格，取最高SKU价格；\n",
    "--提取商品的主要属性信息main_properties，包括材质material、工艺craftsmanship，流行元素fashion_element、风格style、尺寸size、单位重量unit_weight，格式为Json；\n",
    "--将提取的信息以Json格式输出，分别为中文版和英文版两个Json\n",
    "#Constrains\n",
    "--提取的信息中不能含有跨境、代发、批发、中国制造的相关词汇（original_title字段除外）\n",
    "--google和shopify商品类别是具有层级关系的完整类目\n",
    "--价格、重量的格式为数字+单位，例如5元、5Kg，如果未找到，则用空字符’’替代；价格不需要币种和汇率转换\n",
    "--只输出中文版Json和英文版Json即可，不需要其他信息输出\n",
    "#Example\n",
    "输出Json格式示例：{\"original_title\": “××\", \"description\": \"××\", \"brief_title\": \"××”, \"seo_title\": \"××”,  \"google_category\": \"××\", “shopify_category\": \"××\", \"type\": “××”, \"tags\": “××,××,××”,  \"gender\": “××”,  \"age_group\": “××”,  \"adword_group\": “××”, \"adword_labels\": “××”, \"mpn_code\": “××”, \"sku_details\": {“属性名称A\": { “属性1\": \"价格\", “属性2\": \"价格\"}, \"属性名称B\": { “属性1\": ‘价格', “属性2\": “价格\"} }, \"highest_price\": “价格\", \"main_properties\": { \"material\": \"×××\", \"craftsmanship\": \"×××\", \"fashion_element\": \"×××\", \"style\": \"×××\", \"size\": ”×××”, \"unit_weight\": ”×××”}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "RUMNVNTY 不锈钢情侣刻字手链欧美潮流嘻哈INS风情人节礼物私人定\n",
    "\n",
    "0条评价\n",
    "90天内\n",
    "300+\n",
    "PCS成交\n",
    "举报\n",
    "批发\n",
    "一件代发\n",
    "\n",
    "价格\n",
    "起批量\n",
    "¥\n",
    "6.50\n",
    "~\n",
    "¥\n",
    "8.00\n",
    "2PCS起批\n",
    "优惠\n",
    "满199元包邮\n",
    "1件混批\n",
    "查看\n",
    "服务\n",
    "极速退款\n",
    "7天包换\n",
    "材质保障\n",
    "晚发必赔\n",
    "物流\n",
    "浙江金华\n",
    "至\n",
    "请选择\n",
    "运费 : 选择收货地\n",
    "承诺72小时发货\n",
    "更多\n",
    "颜色\n",
    "钢色\n",
    "6.50元\n",
    "9573PCS可售\n",
    "0\n",
    " \t \n",
    "18K炉内真金\n",
    "8.00元\n",
    "9540PCS可售\n",
    "0\n",
    " \t \n",
    "炉内玫瑰金\n",
    "8.00元\n",
    "9876PCS可售\n",
    "0\n",
    " \t \n",
    "黑色\n",
    "8.00元\n",
    "976PCS可售\n",
    "跨境属性\n",
    "跨境包裹重量\n",
    "0.08kg\n",
    "单位重量\n",
    "0.08kg\n",
    "商品属性\n",
    "材质\n",
    "钛钢\n",
    "处理工艺\n",
    "电镀\n",
    "品牌\n",
    "RUMNVNTY\n",
    "样式\n",
    "男女通用\n",
    "造型\n",
    "心形\n",
    "适用送礼场合\n",
    "旅游纪念\n",
    "货号\n",
    "DH042\n",
    "产地\n",
    "广州\n",
    "主要下游平台\n",
    "淘宝,京东,ebay,PDD,亚马逊,wish,快手,LINIO,SHEIN,速卖通,天猫,独立站,LAZADA,拼多多,shopee,抖音,垂类电商\n",
    "颜色\n",
    "钢色,18K炉内真金,炉内玫瑰金,黑色\n",
    "有可授权的自有品牌\n",
    "是\n",
    "是否跨境出口专供货源\n",
    "是\n",
    "流行元素\n",
    "椭圆\n",
    "上市年份/季节\n",
    "2022年冬季\n",
    "风格\n",
    "个性\n",
    "风格分类\n",
    "个性风潮\n",
    "主要销售地区\n",
    "非洲,欧洲,南美,东南亚,北美,东北亚,中东,其他\n",
    "适用人群\n",
    "情侣式\n",
    "流行元素分类\n",
    "几何\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7rHDWq8lbfYgJJXC8jsqVCSv3MfNb at 0x7feca80b3e30> JSON: {\n",
       "  \"id\": \"chatcmpl-7rHDWq8lbfYgJJXC8jsqVCSv3MfNb\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1692931922,\n",
       "  \"model\": \"gpt-4-0314\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"{\\n  \\\"original_title\\\": \\\"RUMNVNTY \\u4e0d\\u9508\\u94a2\\u60c5\\u4fa3\\u523b\\u5b57\\u624b\\u94fe\\u6b27\\u7f8e\\u6f6e\\u6d41\\u563b\\u54c8INS\\u98ce\\u60c5\\u4eba\\u8282\\u793c\\u7269\\u79c1\\u4eba\\u5b9a\\\",\\n  \\\"description\\\": \\\"\\u4e0d\\u9508\\u94a2\\u60c5\\u4fa3\\u523b\\u5b57\\u624b\\u94fe\\uff0c\\u6b27\\u7f8e\\u6f6e\\u6d41\\u563b\\u54c8INS\\u98ce\\uff0c\\u9002\\u5408\\u60c5\\u4eba\\u8282\\u793c\\u7269\\uff0c\\u79c1\\u4eba\\u5b9a\\u5236\\\",\\n  \\\"brief_title\\\": \\\"\\u4e0d\\u9508\\u94a2\\u60c5\\u4fa3\\u523b\\u5b57\\u624b\\u94fe\\\",\\n  \\\"seo_title\\\": \\\"RUMNVNTY - \\u4e0d\\u9508\\u94a2\\u60c5\\u4fa3\\u523b\\u5b57\\u624b\\u94fe, \\u6b27\\u7f8e\\u6f6e\\u6d41\\u563b\\u54c8INS\\u98ce, \\u9002\\u7528\\u4e8e\\u60c5\\u4eba\\u8282\\u793c\\u7269\\\",\\n  \\\"google_category\\\": \\\"\\u9996\\u9970\\u4e0e\\u914d\\u4ef6 > \\u624b\\u94fe\\\",\\n  \\\"shopify_category\\\": \\\"\\u9996\\u9970\\u4e0e\\u914d\\u4ef6 > \\u624b\\u94fe\\\",\\n  \\\"type\\\": \\\"\\u624b\\u94fe\\\",\\n  \\\"tags\\\": \\\"\\u4e0d\\u9508\\u94a2,\\u60c5\\u4fa3,\\u523b\\u5b57,\\u624b\\u94fe,\\u793c\\u7269\\\",\\n  \\\"gender\\\": \\\"unisex\\\",\\n  \\\"age_group\\\": \\\"adult\\\",\\n  \\\"adword_group\\\": \\\"\\u624b\\u94fe,\\u60c5\\u4fa3,\\u793c\\u7269\\\",\\n  \\\"adword_labels\\\": \\\"\\u4e0d\\u9508\\u94a2,\\u523b\\u5b57,\\u60c5\\u4eba\\u8282,\\u6b27\\u7f8e\\u6f6e\\u6d41,\\u79c1\\u4eba\\u5b9a\\u5236\\\",\\n  \\\"mpn_code\\\": \\\"DH042\\\",\\n  \\\"sku_details\\\": {\\n    \\\"\\u989c\\u8272\\\": {\\n      \\\"\\u94a2\\u8272\\\": \\\"6.50\\u5143\\\",\\n      \\\"18K\\u7089\\u5185\\u771f\\u91d1\\\": \\\"8.00\\u5143\\\",\\n      \\\"\\u7089\\u5185\\u73ab\\u7470\\u91d1\\\": \\\"8.00\\u5143\\\",\\n      \\\"\\u9ed1\\u8272\\\": \\\"8.00\\u5143\\\"\\n    }\\n  },\\n  \\\"highest_price\\\": \\\"8.00\\u5143\\\",\\n  \\\"main_properties\\\": {\\n    \\\"material\\\": \\\"\\u949b\\u94a2\\\",\\n    \\\"craftsmanship\\\": \\\"\\u7535\\u9540\\\",\\n    \\\"fashion_element\\\": \\\"\\u692d\\u5706\\\",\\n    \\\"style\\\": \\\"\\u4e2a\\u6027\\u98ce\\u6f6e\\\",\\n    \\\"size\\\": \\\"\\\",\\n    \\\"unit_weight\\\": \\\"0.08kg\\\"\\n  }\\n}\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 1497,\n",
       "    \"completion_tokens\": 480,\n",
       "    \"total_tokens\": 1977\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = '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'\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4-0314\",\n",
    "#   max_tokens=100,\n",
    "#   temperature=0,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": f\"{system}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/bv/1ly9grbd6w143ngs2zd7406h0000gq/T/ipykernel_15741/2834172697.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     28\u001B[0m     {\n\u001B[1;32m     29\u001B[0m         \u001B[0;34m\"role\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"assistant\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         \u001B[0;34m\"content\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnull\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m         \"function_call\": {\n\u001B[1;32m     32\u001B[0m             \u001B[0;34m\"name\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"calculate_sum\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "openai.api_key = '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'\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4-0314\",\n",
    "#   max_tokens=100,\n",
    "#   temperature=0,\n",
    "  messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"请帮我计算5和7的和。\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": None,\n",
    "        \"function_call\": {\n",
    "            \"name\": \"calculate_sum\",\n",
    "            \"arguments\": \"{\\\"a\\\": 5, \\\"b\\\": 7}\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7rH5ApdQfdfhyAbQwLUGwdXPgUix8 at 0x7feca80c4c50> JSON: {\n",
       "  \"id\": \"chatcmpl-7rH5ApdQfdfhyAbQwLUGwdXPgUix8\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1692931404,\n",
       "  \"model\": \"gpt-4-0314\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"5\\u548c7\\u7684\\u548c\\u662f12\\u3002\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 40,\n",
       "    \"completion_tokens\": 8,\n",
       "    \"total_tokens\": 48\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_title': 'rumnvnty 不锈钢情侣刻字手链欧美潮流嘻哈ins风情人节礼物私人定',\n",
       " 'description': '不锈钢情侣刻字手链，欧美潮流嘻哈ins风，适合情人节礼物，私人定制',\n",
       " 'brief_title': '不锈钢情侣刻字手链',\n",
       " 'seo_title': 'rumnvnty - 不锈钢情侣刻字手链, 欧美潮流嘻哈ins风, 适用于情人节礼物',\n",
       " 'google_category': '首饰与配件 > 手链',\n",
       " 'shopify_category': '首饰与配件 > 手链',\n",
       " 'type': '手链',\n",
       " 'tags': '不锈钢,情侣,刻字,手链,礼物',\n",
       " 'gender': 'unisex',\n",
       " 'age_group': 'adult',\n",
       " 'adword_group': '手链,情侣,礼物',\n",
       " 'adword_labels': '不锈钢,刻字,情人节,欧美潮流,私人定制',\n",
       " 'mpn_code': 'dh042',\n",
       " 'sku_details': {'颜色': {'钢色': '6.50元',\n",
       "   '18k炉内真金': '8.00元',\n",
       "   '炉内玫瑰金': '8.00元',\n",
       "   '黑色': '8.00元'}},\n",
       " 'highest_price': '8.00元',\n",
       " 'main_properties': {'material': '钛钢',\n",
       "  'craftsmanship': '电镀',\n",
       "  'fashion_element': '椭圆',\n",
       "  'style': '个性风潮',\n",
       "  'size': '',\n",
       "  'unit_weight': '0.08kg'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js_str = '{\\n  \\\"original_title\\\": \\\"rumnvnty 不锈钢情侣刻字手链欧美潮流嘻哈ins风情人节礼物私人定\\\",\\n  \\\"description\\\": \\\"不锈钢情侣刻字手链，欧美潮流嘻哈ins风，适合情人节礼物，私人定制\\\",\\n  \\\"brief_title\\\": \\\"不锈钢情侣刻字手链\\\",\\n  \\\"seo_title\\\": \\\"rumnvnty - 不锈钢情侣刻字手链, 欧美潮流嘻哈ins风, 适用于情人节礼物\\\",\\n  \\\"google_category\\\": \\\"首饰与配件 > 手链\\\",\\n  \\\"shopify_category\\\": \\\"首饰与配件 > 手链\\\",\\n  \\\"type\\\": \\\"手链\\\",\\n  \\\"tags\\\": \\\"不锈钢,情侣,刻字,手链,礼物\\\",\\n  \\\"gender\\\": \\\"unisex\\\",\\n  \\\"age_group\\\": \\\"adult\\\",\\n  \\\"adword_group\\\": \\\"手链,情侣,礼物\\\",\\n  \\\"adword_labels\\\": \\\"不锈钢,刻字,情人节,欧美潮流,私人定制\\\",\\n  \\\"mpn_code\\\": \\\"dh042\\\",\\n  \\\"sku_details\\\": {\\n    \\\"颜色\\\": {\\n      \\\"钢色\\\": \\\"6.50元\\\",\\n      \\\"18k炉内真金\\\": \\\"8.00元\\\",\\n      \\\"炉内玫瑰金\\\": \\\"8.00元\\\",\\n      \\\"黑色\\\": \\\"8.00元\\\"\\n    }\\n  },\\n  \\\"highest_price\\\": \\\"8.00元\\\",\\n  \\\"main_properties\\\": {\\n    \\\"material\\\": \\\"钛钢\\\",\\n    \\\"craftsmanship\\\": \\\"电镀\\\",\\n    \\\"fashion_element\\\": \\\"椭圆\\\",\\n    \\\"style\\\": \\\"个性风潮\\\",\\n    \\\"size\\\": \\\"\\\",\\n    \\\"unit_weight\\\": \\\"0.08kg\\\"\\n  }\\n}'\n",
    "json.loads(js_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function getenv in module os:\n",
      "\n",
      "getenv(key, default=None)\n",
      "    Get an environment variable, return None if it doesn't exist.\n",
      "    The optional second argument can specify an alternate default.\n",
      "    key, default and the result are str.\n"
     ]
    }
   ],
   "source": [
    "help(os.getenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/fanke.chang/Downloads/id_cluster_precision.csv', sep='\\t', dtype=str).fillna('')\n",
    "df['admin_division_1'] = df.query_address_component.apply(lambda x: json.loads(x).get('admin_division_1'))\n",
    "df['admin_division_2'] = df.query_address_component.apply(lambda x: json.loads(x).get('admin_division_2'))\n",
    "df['admin_division_3'] = df.query_address_component.apply(lambda x: json.loads(x).get('admin_division_3'))\n",
    "df['query_raw_address'] = df.query_address_component.apply(lambda x: json.loads(x).get('raw_address'))\n",
    "df['recall_raw_address'] = df.recall_address_component.apply(lambda x: json.loads(x).get('raw_address'))\n",
    "df.to_csv('/Users/fanke.chang/Downloads/id_cluster_precision_res.csv', sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Sulawesi Selatan\n",
       "1       Sulawesi Selatan\n",
       "2       Sulawesi Selatan\n",
       "3       Sulawesi Selatan\n",
       "4       Sulawesi Selatan\n",
       "              ...       \n",
       "1171          Jawa Barat\n",
       "1172          Jawa Barat\n",
       "1173          Jawa Barat\n",
       "1174          Jawa Barat\n",
       "1175          Jawa Barat\n",
       "Name: admin_division_1, Length: 1176, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['admin_division_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shopify\n",
    "SHOP_URL = '34460e.myshopify.com'\n",
    "API_KEY = '093a3e097bc79f63fe13c683022bc5e2'\n",
    "PASSWORD = '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'\n",
    "# PASSWORD = 'FaW826204'\n",
    "# shop_url = \"https://%s:%s@%s.myshopify.com/admin\" % (API_KEY, PASSWORD, SHOP_NAME)\n",
    "shopify.ShopifyResource.set_site(f\"https://{API_KEY}:{PASSWORD}@{SHOP_URL}/admin\")\n",
    "# shopify.ShopifyResource.set_site(shop_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: 8911564308785\n",
      "Product Title: 2023时尚潮人古埃及法老头像嘻哈吊坠 个性复古男士合金项链批发\n",
      "------\n",
      "Product ID: 8911596683569\n",
      "Product Title: European and American Hip-hop Trendsetters 13mm Flat Bottomed Cuban Chain with Diamond Bracelets for Men and Women Hiphop Gold Plated Necklace Cross-border\n",
      "------\n",
      "Product ID: 8911565455665\n",
      "Product Title: 儿童方向盘模拟驾驶玩具益智电动桌面游戏机躲避赛车闯关大冒险\n",
      "------\n",
      "Product ID: 8911596224817\n",
      "Product Title: 欧美跨境新款首饰爱心镶钻锆石项链简约个性时尚百搭耳饰厂家批发\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "products = shopify.Product.find()\n",
    "for product in products:\n",
    "    print(f\"Product ID: {product.id}\")\n",
    "    print(f\"Product Title: {product.title}\")\n",
    "    # print(f\"Product Body: {product.body_html}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3032645996.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/bv/1ly9grbd6w143ngs2zd7406h0000gq/T/ipykernel_15741/3032645996.py\"\u001B[0;36m, line \u001B[0;32m1\u001B[0m\n\u001B[0;31m    GET https://34460e.myshopify.com/admin/oauth/authorize\u001B[0m\n\u001B[0m            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "GET https://34460e.myshopify.com/admin/oauth/authorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: remote control, remote\n"
     ]
    }
   ],
   "source": [
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "url = 'https://cdn.shopify.com/s/files/1/0824/1273/2721/files/O1CN014RuCnn1lkYW4Ju12V__2211718304857-0-cib.jpg?v=1693838171'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ViTImageProcessor in module transformers.models.vit.image_processing_vit object:\n",
      "\n",
      "class ViTImageProcessor(transformers.image_processing_utils.BaseImageProcessor)\n",
      " |  ViTImageProcessor(do_resize: bool = True, size: Union[Dict[str, int], NoneType] = None, resample: PIL.Image.Resampling = <Resampling.BILINEAR: 2>, do_rescale: bool = True, rescale_factor: Union[int, float] = 0.00392156862745098, do_normalize: bool = True, image_mean: Union[float, List[float], NoneType] = None, image_std: Union[float, List[float], NoneType] = None, **kwargs) -> None\n",
      " |  \n",
      " |  Constructs a ViT image processor.\n",
      " |  \n",
      " |  Args:\n",
      " |      do_resize (`bool`, *optional*, defaults to `True`):\n",
      " |          Whether to resize the image's (height, width) dimensions to the specified `(size[\"height\"],\n",
      " |          size[\"width\"])`. Can be overridden by the `do_resize` parameter in the `preprocess` method.\n",
      " |      size (`dict`, *optional*, defaults to `{\"height\": 224, \"width\": 224}`):\n",
      " |          Size of the output image after resizing. Can be overridden by the `size` parameter in the `preprocess`\n",
      " |          method.\n",
      " |      resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BILINEAR`):\n",
      " |          Resampling filter to use if resizing the image. Can be overridden by the `resample` parameter in the\n",
      " |          `preprocess` method.\n",
      " |      do_rescale (`bool`, *optional*, defaults to `True`):\n",
      " |          Whether to rescale the image by the specified scale `rescale_factor`. Can be overridden by the `do_rescale`\n",
      " |          parameter in the `preprocess` method.\n",
      " |      rescale_factor (`int` or `float`, *optional*, defaults to `1/255`):\n",
      " |          Scale factor to use if rescaling the image. Can be overridden by the `rescale_factor` parameter in the\n",
      " |          `preprocess` method.\n",
      " |      do_normalize (`bool`, *optional*, defaults to `True`):\n",
      " |          Whether to normalize the image. Can be overridden by the `do_normalize` parameter in the `preprocess`\n",
      " |          method.\n",
      " |      image_mean (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_MEAN`):\n",
      " |          Mean to use if normalizing the image. This is a float or list of floats the length of the number of\n",
      " |          channels in the image. Can be overridden by the `image_mean` parameter in the `preprocess` method.\n",
      " |      image_std (`float` or `List[float]`, *optional*, defaults to `IMAGENET_STANDARD_STD`):\n",
      " |          Standard deviation to use if normalizing the image. This is a float or list of floats the length of the\n",
      " |          number of channels in the image. Can be overridden by the `image_std` parameter in the `preprocess` method.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ViTImageProcessor\n",
      " |      transformers.image_processing_utils.BaseImageProcessor\n",
      " |      transformers.image_processing_utils.ImageProcessingMixin\n",
      " |      transformers.utils.hub.PushToHubMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, do_resize: bool = True, size: Union[Dict[str, int], NoneType] = None, resample: PIL.Image.Resampling = <Resampling.BILINEAR: 2>, do_rescale: bool = True, rescale_factor: Union[int, float] = 0.00392156862745098, do_normalize: bool = True, image_mean: Union[float, List[float], NoneType] = None, image_std: Union[float, List[float], NoneType] = None, **kwargs) -> None\n",
      " |      Set elements of `kwargs` as attributes.\n",
      " |  \n",
      " |  normalize(self, image: numpy.ndarray, mean: Union[float, List[float]], std: Union[float, List[float]], data_format: Union[transformers.image_utils.ChannelDimension, str, NoneType] = None, **kwargs) -> numpy.ndarray\n",
      " |      Normalize an image. image = (image - image_mean) / image_std.\n",
      " |      \n",
      " |      Args:\n",
      " |          image (`np.ndarray`):\n",
      " |              Image to normalize.\n",
      " |          mean (`float` or `List[float]`):\n",
      " |              Image mean to use for normalization.\n",
      " |          std (`float` or `List[float]`):\n",
      " |              Image standard deviation to use for normalization.\n",
      " |          data_format (`str` or `ChannelDimension`, *optional*):\n",
      " |              The channel dimension format for the output image. If unset, the channel dimension format of the input\n",
      " |              image is used. Can be one of:\n",
      " |              - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\n",
      " |              - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `np.ndarray`: The normalized image.\n",
      " |  \n",
      " |  preprocess(self, images: Union[ForwardRef('PIL.Image.Image'), numpy.ndarray, ForwardRef('torch.Tensor'), List[ForwardRef('PIL.Image.Image')], List[numpy.ndarray], List[ForwardRef('torch.Tensor')]], do_resize: Union[bool, NoneType] = None, size: Dict[str, int] = None, resample: PIL.Image.Resampling = None, do_rescale: Union[bool, NoneType] = None, rescale_factor: Union[float, NoneType] = None, do_normalize: Union[bool, NoneType] = None, image_mean: Union[float, List[float], NoneType] = None, image_std: Union[float, List[float], NoneType] = None, return_tensors: Union[str, transformers.utils.generic.TensorType, NoneType] = None, data_format: Union[str, transformers.image_utils.ChannelDimension] = <ChannelDimension.FIRST: 'channels_first'>, **kwargs)\n",
      " |      Preprocess an image or batch of images.\n",
      " |      \n",
      " |      Args:\n",
      " |          images (`ImageInput`):\n",
      " |              Image to preprocess.\n",
      " |          do_resize (`bool`, *optional*, defaults to `self.do_resize`):\n",
      " |              Whether to resize the image.\n",
      " |          size (`Dict[str, int]`, *optional*, defaults to `self.size`):\n",
      " |              Dictionary in the format `{\"height\": h, \"width\": w}` specifying the size of the output image after\n",
      " |              resizing.\n",
      " |          resample (`PILImageResampling` filter, *optional*, defaults to `self.resample`):\n",
      " |              `PILImageResampling` filter to use if resizing the image e.g. `PILImageResampling.BILINEAR`. Only has\n",
      " |              an effect if `do_resize` is set to `True`.\n",
      " |          do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):\n",
      " |              Whether to rescale the image values between [0 - 1].\n",
      " |          rescale_factor (`float`, *optional*, defaults to `self.rescale_factor`):\n",
      " |              Rescale factor to rescale the image by if `do_rescale` is set to `True`.\n",
      " |          do_normalize (`bool`, *optional*, defaults to `self.do_normalize`):\n",
      " |              Whether to normalize the image.\n",
      " |          image_mean (`float` or `List[float]`, *optional*, defaults to `self.image_mean`):\n",
      " |              Image mean to use if `do_normalize` is set to `True`.\n",
      " |          image_std (`float` or `List[float]`, *optional*, defaults to `self.image_std`):\n",
      " |              Image standard deviation to use if `do_normalize` is set to `True`.\n",
      " |          return_tensors (`str` or `TensorType`, *optional*):\n",
      " |              The type of tensors to return. Can be one of:\n",
      " |              - Unset: Return a list of `np.ndarray`.\n",
      " |              - `TensorType.TENSORFLOW` or `'tf'`: Return a batch of type `tf.Tensor`.\n",
      " |              - `TensorType.PYTORCH` or `'pt'`: Return a batch of type `torch.Tensor`.\n",
      " |              - `TensorType.NUMPY` or `'np'`: Return a batch of type `np.ndarray`.\n",
      " |              - `TensorType.JAX` or `'jax'`: Return a batch of type `jax.numpy.ndarray`.\n",
      " |          data_format (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`):\n",
      " |              The channel dimension format for the output image. Can be one of:\n",
      " |              - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\n",
      " |              - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\n",
      " |              - Unset: Use the channel dimension format of the input image.\n",
      " |  \n",
      " |  rescale(self, image: numpy.ndarray, scale: float, data_format: Union[transformers.image_utils.ChannelDimension, str, NoneType] = None, **kwargs) -> numpy.ndarray\n",
      " |      Rescale an image by a scale factor. image = image * scale.\n",
      " |      \n",
      " |      Args:\n",
      " |          image (`np.ndarray`):\n",
      " |              Image to rescale.\n",
      " |          scale (`float`):\n",
      " |              The scaling factor to rescale pixel values by.\n",
      " |          data_format (`str` or `ChannelDimension`, *optional*):\n",
      " |              The channel dimension format for the output image. If unset, the channel dimension format of the input\n",
      " |              image is used. Can be one of:\n",
      " |              - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\n",
      " |              - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `np.ndarray`: The rescaled image.\n",
      " |  \n",
      " |  resize(self, image: numpy.ndarray, size: Dict[str, int], resample: PIL.Image.Resampling = <Resampling.BILINEAR: 2>, data_format: Union[transformers.image_utils.ChannelDimension, str, NoneType] = None, **kwargs) -> numpy.ndarray\n",
      " |      Resize an image to `(size[\"height\"], size[\"width\"])`.\n",
      " |      \n",
      " |      Args:\n",
      " |          image (`np.ndarray`):\n",
      " |              Image to resize.\n",
      " |          size (`Dict[str, int]`):\n",
      " |              Dictionary in the format `{\"height\": int, \"width\": int}` specifying the size of the output image.\n",
      " |          resample:\n",
      " |              `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BILINEAR`.\n",
      " |          data_format (`ChannelDimension` or `str`, *optional*):\n",
      " |              The channel dimension format for the output image. If unset, the channel dimension format of the input\n",
      " |              image is used. Can be one of:\n",
      " |              - `\"channels_first\"` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.\n",
      " |              - `\"channels_last\"` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `np.ndarray`: The resized image.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  model_input_names = ['pixel_values']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from transformers.image_processing_utils.BaseImageProcessor:\n",
      " |  \n",
      " |  __call__(self, images, **kwargs) -> transformers.image_processing_utils.BatchFeature\n",
      " |      Preprocess an image or a batch of images.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from transformers.image_processing_utils.ImageProcessingMixin:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  push_to_hub(self, repo_id: str, use_temp_dir: Union[bool, NoneType] = None, commit_message: Union[str, NoneType] = None, private: Union[bool, NoneType] = None, use_auth_token: Union[bool, str, NoneType] = None, max_shard_size: Union[int, str, NoneType] = '10GB', create_pr: bool = False, safe_serialization: bool = False, **deprecated_kwargs) -> str\n",
      " |      Upload the image processor file to the 🤗 Model Hub while synchronizing a local clone of the repo in\n",
      " |      `repo_path_or_name`.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          repo_id (`str`):\n",
      " |              The name of the repository you want to push your image processor to. It should contain your organization name\n",
      " |              when pushing to a given organization.\n",
      " |          use_temp_dir (`bool`, *optional*):\n",
      " |              Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub.\n",
      " |              Will default to `True` if there is no directory named like `repo_id`, `False` otherwise.\n",
      " |          commit_message (`str`, *optional*):\n",
      " |              Message to commit while pushing. Will default to `\"Upload image processor\"`.\n",
      " |          private (`bool`, *optional*):\n",
      " |              Whether or not the repository created should be private.\n",
      " |          use_auth_token (`bool` or `str`, *optional*):\n",
      " |              The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      " |              when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n",
      " |              is not specified.\n",
      " |          max_shard_size (`int` or `str`, *optional*, defaults to `\"10GB\"`):\n",
      " |              Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard\n",
      " |              will then be each of size lower than this size. If expressed as a string, needs to be digits followed\n",
      " |              by a unit (like `\"5MB\"`).\n",
      " |          create_pr (`bool`, *optional*, defaults to `False`):\n",
      " |              Whether or not to create a PR with the uploaded files or directly commit.\n",
      " |          safe_serialization (`bool`, *optional*, defaults to `False`):\n",
      " |              Whether or not to convert the model weights in safetensors format for safer serialization.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      ```python\n",
      " |      from transformers import AutoImageProcessor\n",
      " |      \n",
      " |      image processor = AutoImageProcessor.from_pretrained(\"bert-base-cased\")\n",
      " |      \n",
      " |      # Push the image processor to your namespace with the name \"my-finetuned-bert\".\n",
      " |      image processor.push_to_hub(\"my-finetuned-bert\")\n",
      " |      \n",
      " |      # Push the image processor to an organization with the name \"my-finetuned-bert\".\n",
      " |      image processor.push_to_hub(\"huggingface/my-finetuned-bert\")\n",
      " |      ```\n",
      " |  \n",
      " |  save_pretrained(self, save_directory: Union[str, os.PathLike], push_to_hub: bool = False, **kwargs)\n",
      " |      Save an image processor object to the directory `save_directory`, so that it can be re-loaded using the\n",
      " |      [`~image_processing_utils.ImageProcessingMixin.from_pretrained`] class method.\n",
      " |      \n",
      " |      Args:\n",
      " |          save_directory (`str` or `os.PathLike`):\n",
      " |              Directory where the image processor JSON file will be saved (will be created if it does not exist).\n",
      " |          push_to_hub (`bool`, *optional*, defaults to `False`):\n",
      " |              Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the\n",
      " |              repository you want to push to with `repo_id` (will default to the name of `save_directory` in your\n",
      " |              namespace).\n",
      " |          kwargs:\n",
      " |              Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n",
      " |  \n",
      " |  to_dict(self) -> Dict[str, Any]\n",
      " |      Serializes this instance to a Python dictionary.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `Dict[str, Any]`: Dictionary of all the attributes that make up this image processor instance.\n",
      " |  \n",
      " |  to_json_file(self, json_file_path: Union[str, os.PathLike])\n",
      " |      Save this instance to a JSON file.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_file_path (`str` or `os.PathLike`):\n",
      " |              Path to the JSON file in which this image_processor instance's parameters will be saved.\n",
      " |  \n",
      " |  to_json_string(self) -> str\n",
      " |      Serializes this instance to a JSON string.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `str`: String containing all the attributes that make up this feature_extractor instance in JSON format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from transformers.image_processing_utils.ImageProcessingMixin:\n",
      " |  \n",
      " |  from_dict(image_processor_dict: Dict[str, Any], **kwargs) from builtins.type\n",
      " |      Instantiates a type of [`~image_processing_utils.ImageProcessingMixin`] from a Python dictionary of parameters.\n",
      " |      \n",
      " |      Args:\n",
      " |          image_processor_dict (`Dict[str, Any]`):\n",
      " |              Dictionary that will be used to instantiate the image processor object. Such a dictionary can be\n",
      " |              retrieved from a pretrained checkpoint by leveraging the\n",
      " |              [`~image_processing_utils.ImageProcessingMixin.to_dict`] method.\n",
      " |          kwargs (`Dict[str, Any]`):\n",
      " |              Additional parameters from which to initialize the image processor object.\n",
      " |      \n",
      " |      Returns:\n",
      " |          [`~image_processing_utils.ImageProcessingMixin`]: The image processor object instantiated from those\n",
      " |          parameters.\n",
      " |  \n",
      " |  from_json_file(json_file: Union[str, os.PathLike]) from builtins.type\n",
      " |      Instantiates a image processor of type [`~image_processing_utils.ImageProcessingMixin`] from the path to a JSON\n",
      " |      file of parameters.\n",
      " |      \n",
      " |      Args:\n",
      " |          json_file (`str` or `os.PathLike`):\n",
      " |              Path to the JSON file containing the parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A image processor of type [`~image_processing_utils.ImageProcessingMixin`]: The image_processor object\n",
      " |          instantiated from that JSON file.\n",
      " |  \n",
      " |  from_pretrained(pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs) from builtins.type\n",
      " |      Instantiate a type of [`~image_processing_utils.ImageProcessingMixin`] from an image processor.\n",
      " |      \n",
      " |      Args:\n",
      " |          pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
      " |              This can be either:\n",
      " |      \n",
      " |              - a string, the *model id* of a pretrained image_processor hosted inside a model repo on\n",
      " |                huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or\n",
      " |                namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.\n",
      " |              - a path to a *directory* containing a image processor file saved using the\n",
      " |                [`~image_processing_utils.ImageProcessingMixin.save_pretrained`] method, e.g.,\n",
      " |                `./my_model_directory/`.\n",
      " |              - a path or url to a saved image processor JSON *file*, e.g.,\n",
      " |                `./my_model_directory/preprocessor_config.json`.\n",
      " |          cache_dir (`str` or `os.PathLike`, *optional*):\n",
      " |              Path to a directory in which a downloaded pretrained model image processor should be cached if the\n",
      " |              standard cache should not be used.\n",
      " |          force_download (`bool`, *optional*, defaults to `False`):\n",
      " |              Whether or not to force to (re-)download the image processor files and override the cached versions if\n",
      " |              they exist.\n",
      " |          resume_download (`bool`, *optional*, defaults to `False`):\n",
      " |              Whether or not to delete incompletely received file. Attempts to resume the download if such a file\n",
      " |              exists.\n",
      " |          proxies (`Dict[str, str]`, *optional*):\n",
      " |              A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\n",
      " |              'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n",
      " |          use_auth_token (`str` or `bool`, *optional*):\n",
      " |              The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n",
      " |              the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      " |          revision (`str`, *optional*, defaults to `\"main\"`):\n",
      " |              The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
      " |              git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n",
      " |              identifier allowed by git.\n",
      " |      \n",
      " |      \n",
      " |              <Tip>\n",
      " |      \n",
      " |              To test a pull request you made on the Hub, you can pass `revision=\"refs/pr/<pr_number>\".\n",
      " |      \n",
      " |              </Tip>\n",
      " |      \n",
      " |          return_unused_kwargs (`bool`, *optional*, defaults to `False`):\n",
      " |              If `False`, then this function returns just the final image processor object. If `True`, then this\n",
      " |              functions returns a `Tuple(image_processor, unused_kwargs)` where *unused_kwargs* is a dictionary\n",
      " |              consisting of the key/value pairs whose keys are not image processor attributes: i.e., the part of\n",
      " |              `kwargs` which has not been used to update `image_processor` and is otherwise ignored.\n",
      " |          subfolder (`str`, *optional*, defaults to `\"\"`):\n",
      " |              In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can\n",
      " |              specify the folder name here.\n",
      " |          kwargs (`Dict[str, Any]`, *optional*):\n",
      " |              The values in kwargs of any keys which are image processor attributes will be used to override the\n",
      " |              loaded values. Behavior concerning key/value pairs whose keys are *not* image processor attributes is\n",
      " |              controlled by the `return_unused_kwargs` keyword parameter.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A image processor of type [`~image_processing_utils.ImageProcessingMixin`].\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      ```python\n",
      " |      # We can't instantiate directly the base class *ImageProcessingMixin* so let's show the examples on a\n",
      " |      # derived class: *CLIPImageProcessor*\n",
      " |      image_processor = CLIPImageProcessor.from_pretrained(\n",
      " |          \"openai/clip-vit-base-patch32\"\n",
      " |      )  # Download image_processing_config from huggingface.co and cache.\n",
      " |      image_processor = CLIPImageProcessor.from_pretrained(\n",
      " |          \"./test/saved_model/\"\n",
      " |      )  # E.g. image processor (or model) was saved using *save_pretrained('./test/saved_model/')*\n",
      " |      image_processor = CLIPImageProcessor.from_pretrained(\"./test/saved_model/preprocessor_config.json\")\n",
      " |      image_processor = CLIPImageProcessor.from_pretrained(\n",
      " |          \"openai/clip-vit-base-patch32\", do_normalize=False, foo=False\n",
      " |      )\n",
      " |      assert image_processor.do_normalize is False\n",
      " |      image_processor, unused_kwargs = CLIPImageProcessor.from_pretrained(\n",
      " |          \"openai/clip-vit-base-patch32\", do_normalize=False, foo=False, return_unused_kwargs=True\n",
      " |      )\n",
      " |      assert image_processor.do_normalize is False\n",
      " |      assert unused_kwargs == {\"foo\": False}\n",
      " |      ```\n",
      " |  \n",
      " |  get_image_processor_dict(pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs) -> Tuple[Dict[str, Any], Dict[str, Any]] from builtins.type\n",
      " |      From a `pretrained_model_name_or_path`, resolve to a dictionary of parameters, to be used for instantiating a\n",
      " |      image processor of type [`~image_processor_utils.ImageProcessingMixin`] using `from_dict`.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
      " |              The identifier of the pre-trained checkpoint from which we want the dictionary of parameters.\n",
      " |          subfolder (`str`, *optional*, defaults to `\"\"`):\n",
      " |              In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can\n",
      " |              specify the folder name here.\n",
      " |      \n",
      " |      Returns:\n",
      " |          `Tuple[Dict, Dict]`: The dictionary(ies) that will be used to instantiate the image processor object.\n",
      " |  \n",
      " |  register_for_auto_class(auto_class='AutoImageProcessor') from builtins.type\n",
      " |      Register this class with a given auto class. This should only be used for custom image processors as the ones\n",
      " |      in the library are already mapped with `AutoImageProcessor `.\n",
      " |      \n",
      " |      <Tip warning={true}>\n",
      " |      \n",
      " |      This API is experimental and may have some slight breaking changes in the next releases.\n",
      " |      \n",
      " |      </Tip>\n",
      " |      \n",
      " |      Args:\n",
      " |          auto_class (`str` or `type`, *optional*, defaults to `\"AutoImageProcessor \"`):\n",
      " |              The auto class to register this new image processor with.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from transformers.utils.hub.PushToHubMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    }
   ],
   "source": [
    "help(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: remote control, remote\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function open in module PIL.Image:\n",
      "\n",
      "open(fp, mode='r', formats=None)\n",
      "    Opens and identifies the given image file.\n",
      "    \n",
      "    This is a lazy operation; this function identifies the file, but\n",
      "    the file remains open and the actual image data is not read from\n",
      "    the file until you try to process the data (or call the\n",
      "    :py:meth:`~PIL.Image.Image.load` method).  See\n",
      "    :py:func:`~PIL.Image.new`. See :ref:`file-handling`.\n",
      "    \n",
      "    :param fp: A filename (string), pathlib.Path object or a file object.\n",
      "       The file object must implement ``file.read``,\n",
      "       ``file.seek``, and ``file.tell`` methods,\n",
      "       and be opened in binary mode.\n",
      "    :param mode: The mode.  If given, this argument must be \"r\".\n",
      "    :param formats: A list or tuple of formats to attempt to load the file in.\n",
      "       This can be used to restrict the set of formats checked.\n",
      "       Pass ``None`` to try all supported formats. You can print the set of\n",
      "       available formats by running ``python3 -m PIL`` or using\n",
      "       the :py:func:`PIL.features.pilinfo` function.\n",
      "    :returns: An :py:class:`~PIL.Image.Image` object.\n",
      "    :exception FileNotFoundError: If the file cannot be found.\n",
      "    :exception PIL.UnidentifiedImageError: If the image cannot be opened and\n",
      "       identified.\n",
      "    :exception ValueError: If the ``mode`` is not \"r\", or if a ``StringIO``\n",
      "       instance is used for ``fp``.\n",
      "    :exception TypeError: If ``formats`` is not ``None``, a list or a tuple.\n"
     ]
    }
   ],
   "source": [
    "help(Image.open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T06:03:29.040376Z",
     "start_time": "2023-09-18T06:03:29.034397Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/fanke.chang/Downloads/part-00000-305f4cde-2990-42ba-b7b4-794cd590b04b-c000.zstd.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T06:00:32.325130Z",
     "start_time": "2023-09-18T06:00:24.383876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                    index_id                         pp_id  \\\n0    aaPH_Risk73de29Fg0a8Jpr  16PH_Risk1692398997299658752   \n1    2bPH_Risk6yDeyBCqj816JL  2fPH_Risk1811706771754475575   \n2    06PH_RiskBAOEeBSvBGEPdj  57PH_Risk1769234615761748012   \n3    d5PH_Riskx42Gl9f9QNbYzV  6ePH_Risk1740553427303810049   \n4    4bPH_Risk1Qlde8HDyoMM4r  81PH_Risk1727338901422893057   \n..                       ...                           ...   \n989  1aPH_RisklZzyWzTkoBWYe8  77PH_Risk1698258829420460034   \n990  c6PH_Risk60VqMptqj8RoyE  77PH_Risk1809202416337838110   \n991  b6PH_RiskBD3NK2cvBG7WkW  7aPH_Risk1788300164320079897   \n992  d3PH_Risky8a933FWJxY1ev  aePH_Risk1800898969242769442   \n993  9fPH_Riskpd8WLOTyagZyBV  ffPH_Risk1725198235712491521   \n\n                                     formatted_address  \\\n0    Tita'S Store, 82, Paliparan I, Dasmarinas City...   \n1    Potol, Tayabas City, Quezon, 4301 South Luzon,...   \n2    Ground Floor, Waltermart Sucat Expression Stat...   \n3    Poblacion 6, Mamburao, Occidental Mindoro, 510...   \n4    210 Paraan Street, Look 1St, Malolos City, Bul...   \n..                                                 ...   \n989  271 Eucalyptus Street, Lamarea Subdivision, Sa...   \n990  Block 16 Lot 2, Ridgepoint Subdivision, Dalig,...   \n991  Ecoverde Homes, Block 14a Lot 24 Qatar Street,...   \n992  Sitio Lana, Ab-Abut, Piddig, Ilocos Norte, 291...   \n993  25 Edison Street, San Manuel, San Jose Del Mon...   \n\n                                           raw_address  \\\n0                        82 paliparan 1.  Tita's Store   \n1                     Brgy. Ibabang Potol Tayabas City   \n2    Dr.a santos ave.brgy San Isidro ground floor w...   \n3                          MAMBURAO OCCIDENTAL MINDORO   \n4    210 Paraan St. Look 1st Malolos City Bulacan (...   \n..                                                 ...   \n989    271 eucalyptus st lamarea subd san pedro laguna   \n990  Block 16 Lot 2 barangay Prinza,Teresa Rizal Ri...   \n991  Lot 24 Blk 14A Qatar St.,Ecoverde Homes,Brgy. ...   \n992                                         Sitio Lana   \n993                                   25 Edison Street   \n\n                                     address_component  \n0    {\"index_id\": \"16PH_Risk1692398997299658752\", \"...  \n1    {\"index_id\": \"2fPH_Risk1811706771754475575\", \"...  \n2    {\"index_id\": \"57PH_Risk1769234615761748012\", \"...  \n3    {\"index_id\": \"6ePH_Risk1740553427303810049\", \"...  \n4    {\"index_id\": \"81PH_Risk1727338901422893057\", \"...  \n..                                                 ...  \n989  {\"index_id\": \"77PH_Risk1698258829420460034\", \"...  \n990  {\"index_id\": \"77PH_Risk1809202416337838110\", \"...  \n991  {\"index_id\": \"7aPH_Risk1788300164320079897\", \"...  \n992  {\"index_id\": \"aePH_Risk1800898969242769442\", \"...  \n993  {\"index_id\": \"ffPH_Risk1725198235712491521\", \"...  \n\n[994 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index_id</th>\n      <th>pp_id</th>\n      <th>formatted_address</th>\n      <th>raw_address</th>\n      <th>address_component</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aaPH_Risk73de29Fg0a8Jpr</td>\n      <td>16PH_Risk1692398997299658752</td>\n      <td>Tita'S Store, 82, Paliparan I, Dasmarinas City...</td>\n      <td>82 paliparan 1.  Tita's Store</td>\n      <td>{\"index_id\": \"16PH_Risk1692398997299658752\", \"...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2bPH_Risk6yDeyBCqj816JL</td>\n      <td>2fPH_Risk1811706771754475575</td>\n      <td>Potol, Tayabas City, Quezon, 4301 South Luzon,...</td>\n      <td>Brgy. Ibabang Potol Tayabas City</td>\n      <td>{\"index_id\": \"2fPH_Risk1811706771754475575\", \"...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>06PH_RiskBAOEeBSvBGEPdj</td>\n      <td>57PH_Risk1769234615761748012</td>\n      <td>Ground Floor, Waltermart Sucat Expression Stat...</td>\n      <td>Dr.a santos ave.brgy San Isidro ground floor w...</td>\n      <td>{\"index_id\": \"57PH_Risk1769234615761748012\", \"...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d5PH_Riskx42Gl9f9QNbYzV</td>\n      <td>6ePH_Risk1740553427303810049</td>\n      <td>Poblacion 6, Mamburao, Occidental Mindoro, 510...</td>\n      <td>MAMBURAO OCCIDENTAL MINDORO</td>\n      <td>{\"index_id\": \"6ePH_Risk1740553427303810049\", \"...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4bPH_Risk1Qlde8HDyoMM4r</td>\n      <td>81PH_Risk1727338901422893057</td>\n      <td>210 Paraan Street, Look 1St, Malolos City, Bul...</td>\n      <td>210 Paraan St. Look 1st Malolos City Bulacan (...</td>\n      <td>{\"index_id\": \"81PH_Risk1727338901422893057\", \"...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>1aPH_RisklZzyWzTkoBWYe8</td>\n      <td>77PH_Risk1698258829420460034</td>\n      <td>271 Eucalyptus Street, Lamarea Subdivision, Sa...</td>\n      <td>271 eucalyptus st lamarea subd san pedro laguna</td>\n      <td>{\"index_id\": \"77PH_Risk1698258829420460034\", \"...</td>\n    </tr>\n    <tr>\n      <th>990</th>\n      <td>c6PH_Risk60VqMptqj8RoyE</td>\n      <td>77PH_Risk1809202416337838110</td>\n      <td>Block 16 Lot 2, Ridgepoint Subdivision, Dalig,...</td>\n      <td>Block 16 Lot 2 barangay Prinza,Teresa Rizal Ri...</td>\n      <td>{\"index_id\": \"77PH_Risk1809202416337838110\", \"...</td>\n    </tr>\n    <tr>\n      <th>991</th>\n      <td>b6PH_RiskBD3NK2cvBG7WkW</td>\n      <td>7aPH_Risk1788300164320079897</td>\n      <td>Ecoverde Homes, Block 14a Lot 24 Qatar Street,...</td>\n      <td>Lot 24 Blk 14A Qatar St.,Ecoverde Homes,Brgy. ...</td>\n      <td>{\"index_id\": \"7aPH_Risk1788300164320079897\", \"...</td>\n    </tr>\n    <tr>\n      <th>992</th>\n      <td>d3PH_Risky8a933FWJxY1ev</td>\n      <td>aePH_Risk1800898969242769442</td>\n      <td>Sitio Lana, Ab-Abut, Piddig, Ilocos Norte, 291...</td>\n      <td>Sitio Lana</td>\n      <td>{\"index_id\": \"aePH_Risk1800898969242769442\", \"...</td>\n    </tr>\n    <tr>\n      <th>993</th>\n      <td>9fPH_Riskpd8WLOTyagZyBV</td>\n      <td>ffPH_Risk1725198235712491521</td>\n      <td>25 Edison Street, San Manuel, San Jose Del Mon...</td>\n      <td>25 Edison Street</td>\n      <td>{\"index_id\": \"ffPH_Risk1725198235712491521\", \"...</td>\n    </tr>\n  </tbody>\n</table>\n<p>994 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T06:00:38.835689Z",
     "start_time": "2023-09-18T06:00:38.825298Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df['hash_id'] = df['index_id'].apply(lambda x: int(hashlib.sha256(x.encode()).hexdigest(), 16))\n",
    "df.sort_values(['hash_id', 'index_id', 'formatted_address']).to_csv('~/Downloads/cluster_result_0918',index=False,sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T06:05:48.758247Z",
     "start_time": "2023-09-18T06:05:48.693180Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "994"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T06:09:05.906520Z",
     "start_time": "2023-09-18T06:09:05.894525Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from paddleocr import PPStructure,draw_structure_result,save_structure_res\n",
    "\n",
    "table_engine = PPStructure(show_log=True, image_orientation=True)\n",
    "\n",
    "save_folder = '~/Downloads'\n",
    "img_path = '/Users/fanke.chang/shop/image_filter/negative/test_form.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "result = table_engine(img)\n",
    "save_structure_res(result, save_folder,os.path.basename(img_path).split('.')[0])\n",
    "\n",
    "for line in result:\n",
    "    line.pop('img')\n",
    "    print(line)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T16:10:45.066555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_folder = '/data/home/fanke.chang/shop/product_coding/image_filter'\n",
    "img_path = '/data/home/fanke.chang/shop/product_coding/image_filter/negative/test_tabel.jpg'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "font_path = 'doc/fonts/simfang.ttf' # PaddleOCR下提供字体包\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "im_show = draw_structure_result(image, result,font_path=font_path)\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('~/Downloads/result.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['产品名称：大号加厚垃圾袋', '款式：平口式']\n",
      "['产品功能： ： 整理、收纳', '材料：全新PE料']\n",
      "['', '']\n",
      "['适用场合：公司/学校/物业/保洁/餐厅/酒店等', '']\n",
      "['', '']\n",
      "['袋子尺寸', '圆桶直径', '方桶周长', '', '桶高']\n",
      "['55*65', '≤35cm', '≤110cm', '', '≤40cm']\n",
      "['60*80', '≤38cm', '', '≤120cm', '≤50cm']\n",
      "['70*80', '≤44cm', '≤140cm', '', '≤50cm']\n",
      "['70*90', '≤44cm', '≤140cm', '', '≤60cm']\n",
      "['80*90', '≤50cm', '≤160cm', '', '≤60cm']\n",
      "['80*100', '≤50cm', '≤160cm', '', '≤70cm']\n",
      "['90*100', '≤58cm', '≤180cm', '', '≤70cm']\n",
      "['90*110', '≤58cm', '≤180cm', '', '≤75cm']\n",
      "['100*110', '≤63cm', '≤200cm', '', '≤75cm']\n",
      "['100*120', '≤63cm', '≤200cm', '', '≤90cm']\n",
      "['120*140', '≤76cm', '≤240cm', '', '≤110cm']\n",
      "['130*140', '≤82cm', '≤260cm', '', '≤110cm']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML内容\n",
    "html_content = '<html><body><table><tbody><tr><td colspan=\"3\">\\u4ea7\\u54c1\\u540d\\u79f0\\uff1a\\u5927\\u53f7\\u52a0\\u539a\\u5783\\u573e\\u888b</td><td colspan=\"2\">\\u6b3e\\u5f0f\\uff1a\\u5e73\\u53e3\\u5f0f</td></tr><tr><td colspan=\"3\">\\u4ea7\\u54c1\\u529f\\u80fd\\uff1a \\uff1a \\u6574\\u7406\\u3001\\u6536\\u7eb3</td><td colspan=\"2\">\\u6750\\u6599\\uff1a\\u5168\\u65b0PE\\u6599</td></tr><tr><td colspan=\"2\"></td><td colspan=\"3\"></td></tr><tr><td colspan=\"4\">\\u9002\\u7528\\u573a\\u5408\\uff1a\\u516c\\u53f8/\\u5b66\\u6821/\\u7269\\u4e1a/\\u4fdd\\u6d01/\\u9910\\u5385/\\u9152\\u5e97\\u7b49</td><td></td></tr><tr><td colspan=\"4\"></td><td></td></tr><tr><td>\\u888b\\u5b50\\u5c3a\\u5bf8</td><td>\\u5706\\u6876\\u76f4\\u5f84</td><td>\\u65b9\\u6876\\u5468\\u957f</td><td></td><td>\\u6876\\u9ad8</td></tr><tr><td>55*65</td><td>\\u226435cm</td><td>\\u2264110cm</td><td></td><td>\\u226440cm</td></tr><tr><td>60*80</td><td>\\u226438cm</td><td></td><td>\\u2264120cm</td><td>\\u226450cm</td></tr><tr><td>70*80</td><td>\\u226444cm</td><td>\\u2264140cm</td><td></td><td>\\u226450cm</td></tr><tr><td>70*90</td><td>\\u226444cm</td><td>\\u2264140cm</td><td></td><td>\\u226460cm</td></tr><tr><td>80*90</td><td>\\u226450cm</td><td>\\u2264160cm</td><td></td><td>\\u226460cm</td></tr><tr><td>80*100</td><td>\\u226450cm</td><td>\\u2264160cm</td><td></td><td>\\u226470cm</td></tr><tr><td>90*100</td><td>\\u226458cm</td><td>\\u2264180cm</td><td></td><td>\\u226470cm</td></tr><tr><td>90*110</td><td>\\u226458cm</td><td>\\u2264180cm</td><td></td><td>\\u226475cm</td></tr><tr><td>100*110</td><td>\\u226463cm</td><td>\\u2264200cm</td><td></td><td>\\u226475cm</td></tr><tr><td>100*120</td><td>\\u226463cm</td><td>\\u2264200cm</td><td></td><td>\\u226490cm</td></tr><tr><td>120*140</td><td>\\u226476cm</td><td>\\u2264240cm</td><td></td><td>\\u2264110cm</td></tr><tr><td>130*140</td><td>\\u226482cm</td><td>\\u2264260cm</td><td></td><td>\\u2264110cm</td></tr></tbody></table></body></html>'  # 请将其替换为您的HTML内容\n",
    "\n",
    "# 使用Beautiful Soup解析HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# 找到表格元素\n",
    "table = soup.find('table')\n",
    "\n",
    "# 初始化一个用于存储表格数据的列表\n",
    "table_data = []\n",
    "\n",
    "# 遍历表格的每一行和每一列，并提取数据\n",
    "for row in table.find_all('tr'):\n",
    "    row_data = []\n",
    "    for cell in row.find_all(['td', 'th']):\n",
    "        row_data.append(cell.get_text())\n",
    "    table_data.append(row_data)\n",
    "\n",
    "# 打印提取的表格数据\n",
    "for row in table_data:\n",
    "    print(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T16:30:27.739022Z",
     "start_time": "2023-09-21T16:30:27.638115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T06:45:47.941303Z",
     "start_time": "2023-09-27T06:45:47.021023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                    master_place_id                       return_id  \\\n0    1663666425_2022-08-05391383098  1663666441_2022-08-05196581694   \n1    1663666425_2022-08-05391383098     1671900013_2022-12-24679858   \n2    1663666425_2022-08-05391383098  1663667278_2022-08-05376893676   \n3    1663666425_2022-08-05391383098  1663666536_2022-08-05104055052   \n4    1663666425_2022-08-05391383098  1663666764_2022-08-05303210712   \n..                              ...                             ...   \n393  1663666742_2022-08-05401702216  1663666556_2022-08-05321990223   \n394  1663666742_2022-08-05401702216  1663665819_2022-08-05222470276   \n395  1663666742_2022-08-05401702216  1663666945_2022-08-05204161522   \n396  1663666742_2022-08-05401702216  1663667130_2022-08-05283053252   \n397  1663666742_2022-08-05401702216  1663667033_2022-08-05132446840   \n\n                    expect_place_id  \\\n0    1663666150_2022-08-05208653345   \n1    1663666150_2022-08-05208653345   \n2    1663666150_2022-08-05208653345   \n3    1663666150_2022-08-05208653345   \n4    1663666150_2022-08-05208653345   \n..                              ...   \n393   1663665799_2022-08-0514452076   \n394   1663665799_2022-08-0514452076   \n395   1663665799_2022-08-0514452076   \n396   1663665799_2022-08-0514452076   \n397   1663665799_2022-08-0514452076   \n\n                              master_formatted_address  \\\n0    Matahari Binjai Supermall, Jalan L Soekarno Ha...   \n1    Matahari Binjai Supermall, Jalan L Soekarno Ha...   \n2    Matahari Binjai Supermall, Jalan L Soekarno Ha...   \n3    Matahari Binjai Supermall, Jalan L Soekarno Ha...   \n4    Matahari Binjai Supermall, Jalan L Soekarno Ha...   \n..                                                 ...   \n393  RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...   \n394  RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...   \n395  RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...   \n396  RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...   \n397  RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...   \n\n                              return_formatted_address  \\\n0    Matahari Binjai Supermall, Jalan Soekarno Hatt...   \n1    Matahari Binjai Supermall, Jalan Soekarno Hatt...   \n2    Matahari Binjai Supermall, Jalan Soekarno Hatt...   \n3    Matahari Binjai Supermall, Jalan Soekarno Hatt...   \n4    Matahari Binjai Supermall, Jalan Soekarno Hatt...   \n..                                                 ...   \n393  Jalan Kedungmegarih, RT.3/RW.1, Dusun Kedungdo...   \n394  Gang Masjid, RT.3/RW.1, Desa Dumpiagung, Kemba...   \n395  Gang Masjid, RT.3/RW.1, Desa Lopang, Kembangba...   \n396  Pak Tampang, RT.3/RW.1, Desa Pelang, Kembangba...   \n397  Blok 1, RT.3/RW.1, Dusun Kedongori, Desa Kedun...   \n\n                              expect_formatted_address  es_score  \n0    Binjai Supermall, Jalan Soekarno Hatta, Tanah ...  5.919355  \n1    Binjai Supermall, Jalan Soekarno Hatta, Tanah ...  5.919355  \n2    Binjai Supermall, Jalan Soekarno Hatta, Tanah ...  5.919355  \n3    Binjai Supermall, Jalan Soekarno Hatta, Tanah ...  5.919355  \n4    Binjai Supermall, Jalan Soekarno Hatta, Tanah ...  5.919355  \n..                                                 ...       ...  \n393  RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...       1.6  \n394  RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...       1.6  \n395  RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...       1.6  \n396  RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...       1.6  \n397  RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...       1.6  \n\n[398 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>master_place_id</th>\n      <th>return_id</th>\n      <th>expect_place_id</th>\n      <th>master_formatted_address</th>\n      <th>return_formatted_address</th>\n      <th>expect_formatted_address</th>\n      <th>es_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1663666425_2022-08-05391383098</td>\n      <td>1663666441_2022-08-05196581694</td>\n      <td>1663666150_2022-08-05208653345</td>\n      <td>Matahari Binjai Supermall, Jalan L Soekarno Ha...</td>\n      <td>Matahari Binjai Supermall, Jalan Soekarno Hatt...</td>\n      <td>Binjai Supermall, Jalan Soekarno Hatta, Tanah ...</td>\n      <td>5.919355</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1663666425_2022-08-05391383098</td>\n      <td>1671900013_2022-12-24679858</td>\n      <td>1663666150_2022-08-05208653345</td>\n      <td>Matahari Binjai Supermall, Jalan L Soekarno Ha...</td>\n      <td>Matahari Binjai Supermall, Jalan Soekarno Hatt...</td>\n      <td>Binjai Supermall, Jalan Soekarno Hatta, Tanah ...</td>\n      <td>5.919355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1663666425_2022-08-05391383098</td>\n      <td>1663667278_2022-08-05376893676</td>\n      <td>1663666150_2022-08-05208653345</td>\n      <td>Matahari Binjai Supermall, Jalan L Soekarno Ha...</td>\n      <td>Matahari Binjai Supermall, Jalan Soekarno Hatt...</td>\n      <td>Binjai Supermall, Jalan Soekarno Hatta, Tanah ...</td>\n      <td>5.919355</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1663666425_2022-08-05391383098</td>\n      <td>1663666536_2022-08-05104055052</td>\n      <td>1663666150_2022-08-05208653345</td>\n      <td>Matahari Binjai Supermall, Jalan L Soekarno Ha...</td>\n      <td>Matahari Binjai Supermall, Jalan Soekarno Hatt...</td>\n      <td>Binjai Supermall, Jalan Soekarno Hatta, Tanah ...</td>\n      <td>5.919355</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1663666425_2022-08-05391383098</td>\n      <td>1663666764_2022-08-05303210712</td>\n      <td>1663666150_2022-08-05208653345</td>\n      <td>Matahari Binjai Supermall, Jalan L Soekarno Ha...</td>\n      <td>Matahari Binjai Supermall, Jalan Soekarno Hatt...</td>\n      <td>Binjai Supermall, Jalan Soekarno Hatta, Tanah ...</td>\n      <td>5.919355</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>393</th>\n      <td>1663666742_2022-08-05401702216</td>\n      <td>1663666556_2022-08-05321990223</td>\n      <td>1663665799_2022-08-0514452076</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...</td>\n      <td>Jalan Kedungmegarih, RT.3/RW.1, Dusun Kedungdo...</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>1663666742_2022-08-05401702216</td>\n      <td>1663665819_2022-08-05222470276</td>\n      <td>1663665799_2022-08-0514452076</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...</td>\n      <td>Gang Masjid, RT.3/RW.1, Desa Dumpiagung, Kemba...</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>1663666742_2022-08-05401702216</td>\n      <td>1663666945_2022-08-05204161522</td>\n      <td>1663665799_2022-08-0514452076</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...</td>\n      <td>Gang Masjid, RT.3/RW.1, Desa Lopang, Kembangba...</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>1663666742_2022-08-05401702216</td>\n      <td>1663667130_2022-08-05283053252</td>\n      <td>1663665799_2022-08-0514452076</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...</td>\n      <td>Pak Tampang, RT.3/RW.1, Desa Pelang, Kembangba...</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>1663666742_2022-08-05401702216</td>\n      <td>1663667033_2022-08-05132446840</td>\n      <td>1663665799_2022-08-0514452076</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Sido Mukti, K...</td>\n      <td>Blok 1, RT.3/RW.1, Dusun Kedongori, Desa Kedun...</td>\n      <td>RT.3/RW.1, Dsn. Kedungglonggong, Ds. Sidomukti...</td>\n      <td>1.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>398 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T10:31:38.362908Z",
     "start_time": "2023-09-27T10:31:38.350038Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
